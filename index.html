<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Simple WebRTC Voice 1-to-1 Demo</title>
    <style>
      body {
        font-family: Inter, system-ui, Segoe UI, Arial;
        margin: 24px;
      }
      .card {
        max-width: 720px;
        margin: 0 auto;
        border: 1px solid #eee;
        padding: 18px;
        border-radius: 8px;
        box-shadow: 0 6px 18px rgba(0, 0, 0, 0.03);
      }
      label {
        display: block;
        margin-top: 8px;
      }
      input,
      button {
        padding: 8px 12px;
        font-size: 15px;
      }
      .row {
        display: flex;
        gap: 8px;
        margin-top: 12px;
      }
      #log {
        white-space: pre-wrap;
        background: #fafafa;
        border: 1px solid #eee;
        padding: 10px;
        height: 140px;
        overflow: auto;
        margin-top: 12px;
      }
    </style>
  </head>
  <body>
    <div class="card">
      <h2>WebRTC Voice 1-to-many</h2>
      <p>
        Enter a room name (same on both tabs/devices). Allow microphone when
        prompted. One side clicks <strong>Call</strong>, the other sees an
        incoming call button <strong>Accept</strong>.
      </p>

      <label
        >Signaling server (default uses same host):
        <input
          id="serverUrl"
          value="wss://discovering-webrtc.onrender.com"
          style="width: 100%"
        />
      </label>

      <label
        >Room name:
        <input
          id="room"
          placeholder="room123"
          style="width: 100%"
          value="room"
        />
      </label>

      <div class="row">
        <button id="joinBtn">Join Room</button>
        <button id="muteBtn">Mute</button>
      </div>

      <h4>Local / Remote</h4>
      <p>
        <strong>Local mic:</strong> <span id="localState">not started</span
        ><br />
        <strong>Remote audio:</strong> <span id="remoteState">no stream</span>
      </p>

      <div id="log"></div>
    </div>
  </body>
  <script>
    // Minimal WebRTC voice 1-to-Many client
    let localStream = null;
    let PCs = new Map(); // ID -> PC
    let mute = false;
    let MyId = null;
    let ws = null;
    let room = null;

    const logEl = document.getElementById('log');
    function log(...args) {
      console.log(...args);
      logEl.textContent +=
        args
          .map((a) => (typeof a === 'object' ? JSON.stringify(a) : String(a)))
          .join(' ') + '\n';
      logEl.scrollTop = logEl.scrollHeight;
    }

    const serverUrlInput = document.getElementById('serverUrl');
    const roomInput = document.getElementById('room');
    const joinBtn = document.getElementById('joinBtn');
    const muteBtn = document.getElementById('muteBtn');
    muteBtn.disabled = true;
    const incomingDiv = document.getElementById('incoming');
    const localState = document.getElementById('localState');
    const remoteState = document.getElementById('remoteState');

    joinBtn.addEventListener('click', async () => {
      // prepare local audio, but don't create offer yet
      try {
        localStream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        localState.textContent = 'ready';
        log('Local audio ready');
      } catch (e) {
        alert('Microphone permission required: ' + e.message);
        log('getUserMedia failed', e);
        return;
      }
      const url = serverUrlInput.value.trim();
      room = roomInput.value.trim();
      if (!room) {
        alert('Enter room name');
        return;
      }
      ws = new WebSocket(url);
      muteBtn.disabled = false;
      ws.addEventListener('open', async () => {
        log('My WS open');
        ws.send(JSON.stringify({ type: 'join', room }));
        joinBtn.disabled = true;
      });

      ws.addEventListener('message', async (ev) => {
        const msg = JSON.parse(ev.data);
        log('ws<-', msg);

        if (msg.type === 'joined') {
          // backend send all IDs of room members
          // then we open a connection with each peer in a room
          MyId = msg.asingnedId;
          log('Joined room with id', room, MyId);
          // must be connection for each Peer Existing
          msg.peersIDs.forEach(async (Id) => {
            let pc = await startPeerConnection(Id);
            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);
            log('Created offer');
            ws.send(
              JSON.stringify({
                type: 'offer',
                room,
                sdp: pc.localDescription,
                source: MyId,
                target: Id,
              })
            );
          });
        } else if (msg.type === 'offer') {
          // incoming call
          let pc = await startPeerConnection(msg.source);
          await pc.setRemoteDescription(new RTCSessionDescription(msg.sdp));
          console.log('sdp is => ', msg.sdp);
          const answer = await pc.createAnswer();
          await pc.setLocalDescription(answer);
          ws.send(
            JSON.stringify({
              type: 'answer',
              room,
              sdp: pc.localDescription,
              source: MyId,
              target: msg.source,
            })
          );
          log('Sent answer');
        } else if (msg.type === 'answer') {
          let pc = PCs.get(msg.source);
          await pc.setRemoteDescription(new RTCSessionDescription(msg.sdp));
          log('Set remote answer');
        } else if (msg.type === 'candidate') {
          if (PCs.get(msg.source)) {
            try {
              let pc = PCs.get(msg.source);
              await pc.addIceCandidate(msg.candidate);
              log('Added remote ICE candidate');
            } catch (e) {
              log('Error addIce', e);
            }
          }
        } else if (msg.type === 'leave') {
          log('One Peer left');
          PCs.get(msg.source).close();
          PCs.delete(msg.source);
          const audio = document.getElementById(`audio-${msg.source}`);
          if (audio) audio.remove();
          if (PCs.size === 0) {
            cleanup();
          }
        }
      });

      ws.addEventListener('close', () => {
        log('My WS closed');
      });
      ws.addEventListener('error', (e) => {
        log('My WS error', e);
      });
    });

    muteBtn.addEventListener('click', async () => {
      if (!localStream) {
        mute != mute;
        return;
      }
      const audioTrack = localStream.getAudioTracks()[0];
      audioTrack.enabled = !audioTrack.enabled;
      log('mic is Muted', !audioTrack.enabled);
      audioTrack.enabled
        ? (muteBtn.innerText = 'Mute')
        : (muteBtn.innerText = 'unMute');
    });

    async function startPeerConnection(Id) {
      if (PCs.get(Id)) return PCs.get(Id);
      let tempPc = new RTCPeerConnection({
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          // add TURN here if you have one: {urls:'turn:turn.example.com', username:'u', credential:'p'}
        ],
      });
      tempPc.Id = Id;
      PCs.set(Id, tempPc);

      tempPc.onicecandidate = function (ev) {
        if (ev.candidate) {
          log('Local ICE candidate', ev.candidate);
          console.log('source ', MyId);
          ws.send(
            JSON.stringify({
              type: 'candidate',
              room,
              candidate: ev.candidate,
              source: MyId,
              target: tempPc.Id,
            })
          );
        }
      };

      tempPc.ontrack = (ev) => {
        log('Remote track', ev.streams);
        let audio = document.createElement('audio');
        audio.autoplay = true;
        audio.srcObject = ev.streams[0];
        audio.id = `audio-${tempPc.Id}`;
        document.body.appendChild(audio);
        remoteState.textContent = 'playing';
      };

      // add local audio track
      if (localStream) {
        for (const t of localStream.getTracks())
          tempPc.addTrack(t, localStream);
      } else {
        try {
          console.log('forget the NAVVVVVVVVVV');
          localStream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          for (const t of localStream.getTracks())
            tempPc.addTrack(t, localStream);
        } catch (e) {
          log('Could not get mic', e);
        }
      }
      return tempPc;
    }

    function cleanup() {
      log('i will clean Up');
      for (const pc of PCs.values()) {
        pc.close();
      }
      PCs.clear();
      remoteState.textContent = 'no stream';
    }
  </script>
</html>
